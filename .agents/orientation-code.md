# Orientation: Code and Its Relationship to the LaTeX Document

> **Quick start:**
> - Read this before editing Python code or adding/changing figures.
> - Covers: code layout, module roles, figure--code integration, naming conventions, data pipeline.
> - See also: [orientation-latex-math.md](orientation-latex-math.md) for LaTeX structure and macros; [codeinfo-spec.md](codeinfo-spec.md) for the `%% CodeInfo:` annotation format.

This document describes the code in this repo, how it relates to the mathematics in the LaTeX source, and the long-term vision for tight code--document integration.

---

## The overarching goal

**Every figure, table, and numerical result that appears in `SolvingMicroDSOPs.pdf` should ultimately be generated by code that lives in this repository.**

The aspiration is a fully reproducible document where:

1. The mathematical theory is stated precisely in LaTeX.
2. Python code implements that theory, using variable and function names that mirror the LaTeX macros (e.g. `\vEndPrd` in the math corresponds to `vEndPrd()` in the code).
3. Running the code produces every figure and table that the LaTeX document includes.
4. Changing a parameter or method in the code and recompiling the LaTeX yields a self-consistent updated document.

This is not yet fully achieved. The current state is a **mix of code-generated and legacy-static outputs**, described below. Any work you do should move the repo closer to this goal.

---

## Code layout

```
Code/
├── Python/
│   ├── StructEstimation.py          # Structural estimation (SMM)
│   ├── solution.py                  # Period/Stage/Perch solution containers
│   ├── resources.py                 # Utilities, distributions, grids
│   ├── endOfPrd.py                  # End-of-period value functions
│   ├── SolvingMicroDSOP_private_withBrentQToo.py   # Main solution methods
│   ├── gothic_class.ipynb           # Legacy end-of-period class notebook (deprecated; see endOfPrd.py)
│   ├── resources.ipynb              # Resources module notebook
│   ├── endOfPrd.ipynb               # EndOfPrd module notebook
│   ├── SolvingMicroDSOP_private_withBrentQToo.ipynb # Full solution notebook
│   └── snippets/
│       ├── building_pile_backward.py    # Pile/backward induction implementation
│       ├── setup.py                     # Model setup pseudocode
│       ├── equiprobable-make.py         # Discrete approximation
│       ├── equiprobable-max-using.py    # Maximization using discrete approx
│       └── ...
├── Stata/
│   ├── doAll.do                     # Master script
│   ├── SelectVarsUsingSCF*.do       # Extract variables from SCF waves
│   ├── AppendDataUsingSCF1992_2007.do  # Combine all SCF waves
│   └── WIRatioPopulation.do         # Compute wealth-to-income ratios
│
Code-private/                        # Legacy implementations (Matlab, Mathematica)
│   ├── Matlab/                      # Original Matlab code (100+ .m files)
│   ├── Mathematica/                 # Mathematica code
│   └── Python/                      # Older Python versions
```

---

## What each Python module does

### `StructEstimation.py` — Structural estimation

Implements Simulated Method of Moments (SMM) estimation:

- Reads empirical wealth-to-income ratio medians from SCF data (processed by Stata).
- Simulates a population of consumers using HARK's `ConsIndShockModel`.
- Minimizes the distance between simulated and empirical medians by searching over CRRA and a discount-factor adjustment parameter.
- **Generates**: `Figures/SMMcontour.pdf`, `Figures/Sensitivity.pdf`, `Tables/estimate_results.csv`, `Tables/bootstrap_results.csv`.

This is the **most mature code--document link**: the figures and tables it produces are directly `\includegraphics`-ed and `\input`-ed in the LaTeX.

### `solution.py` — Solution data structures

Defines `PeriodSolution`, `Stage`, and `Perch` classes that mirror the LaTeX notation for the period decomposition. Supports retrieval syntax like `S[t]['Shr']['cntn'].v(a)`, which parallels the mathematical notation `\vFunc_{\StgName{Shr}}(\aNrm)`. Perch objects carry short attribute names with Unicode delta: `.v` (value), `.c` (consumption), `.cδ` (consumed function, nearly linear), `.vδ` (marginal value w.r.t. state).

### `resources.py` — Numerical building blocks

Core utilities shared across the codebase:

- `DiscreteApproximation` / `DiscreteApproximationToMeanOneLogNormal` — discretize continuous shock distributions (corresponds to quadrature discussion in the document).
- `Utility`, `UtilityExponential`, `UtilityWithCMin` — CRRA utility function and its derivatives, matching `\uFunc` in the document.
- `get_improved_grid()` — multi-exponential grid construction for interpolation.

### `endOfPrd.py` — End-of-period value functions

Implements the key objects from the theory:

| Code | LaTeX | Description |
|------|-------|-------------|
| `vEndPrd(a)` | `\vEndPrd(\aNrm)` | End-of-period value function |
| `vCntnδ(a)` | `\vEndPrd^{\delta a}(\aNrm)` | Marginal end-of-period value |
| `cCntn(a)` | `\cCntn(\aNrm)` | Continuation consumption function |

### `SolvingMicroDSOP_private_withBrentQToo.py` — Full solution walkthrough

The largest module. Reproduces the numerical methods from the document:

- Discrete approximation of shocks.
- Direct value-function maximization (brute force).
- FOC / Euler-equation methods.
- Endogenous Grid Method (EGM).
- Multi-period backward induction.
- Portfolio choice with risky and risk-free assets.
- Cross-validation against HARK's `PortfolioConsumerType`.

### Snippets (`Code/Python/snippets/`)

Small, self-contained scripts that correspond to specific passages in the LaTeX:

- `building_pile_backward.py` implements the "Pile" data structure from `_sectn-solving-the-next.tex`.
- `pseudo-model-setup-prd*.py` mirrors the pseudocode in the setup sections.
- `equiprobable-*.py` implements discrete approximation utilities.

---

## The data pipeline

```
SCF microdata (external)
        │
        ▼
  Stata (Code/Stata/doAll.do)
        │  extracts, appends, computes W/I ratios
        ▼
  Data/Constructed/WIRATIO_Population.dta
  Data/Constructed/SCFdata.txt
        │
        ▼
  Python (StructEstimation.py)
        │  reads empirical moments, runs SMM
        ▼
  Figures/SMMcontour.pdf    Tables/estimate_results.csv
  Figures/Sensitivity.pdf   Tables/bootstrap_results.csv
        │
        ▼
  LaTeX (\includegraphics, \input)
        │
        ▼
  SolvingMicroDSOPs.pdf
```

---

## Current state of code--figure integration

### Figures generated by code (ready)

| Figure file | Generated by | LaTeX section |
|------------|-------------|--------------|
| `Figures/SMMcontour.pdf` | `StructEstimation.py` | Structural Estimation |
| `Figures/Sensitivity.pdf` | `StructEstimation.py` | Structural Estimation |

### Figures that are static / legacy (not yet generated by repo code)

Most `.eps` files in `Figures/` were originally generated by **MATLAB code** in `Code-private/Matlab/` or **Mathematica code** in `Code-private/Mathematica/`. These include plots of:

- Consumption functions (various periods, with/without constraints).
- Value functions and their piecewise structure.
- Discrete approximation diagrams.
- Interpolation illustrations.

**These are the primary target for future code--document integration**: replace each static `.eps` with a Python script in `Code/Python/` that generates the equivalent figure.

### Tables generated by code

- `Tables/estimate_results.csv` and `Tables/bootstrap_results.csv` from `StructEstimation.py`.
- `Tables/EstResults.tex` is a hand-formatted LaTeX table that incorporates those results.

---

## Dependencies

The Python code depends on:

- **numpy**, **scipy** (optimization, interpolation, statistics)
- **matplotlib** (plotting)
- **[HARK](https://github.com/econ-ark/HARK)** (Heterogeneous Agents Resources and toolKit) — provides `ConsIndShockModel`, `PortfolioConsumerType`, and related infrastructure.

There is a `do_all.py` at the repo root that offers an interactive menu for running the structural estimation at different resource levels.

The Stata code requires access to the raw SCF data files (not included in the repo).

---

## Naming conventions: code mirrors math

A deliberate design principle is that **code identifiers should parallel LaTeX macro names**:

| LaTeX macro | Python name | Meaning |
|------------|-------------|---------|
| `\DiscFac` | `DiscFac` | Discount factor |
| `\CRRA` | `CRRA` | Relative risk aversion |
| `\Rfree` | `Rfree` | Risk-free gross return |
| `\vEndPrd` | `vEndPrd` | End-of-period value function |
| `\cNrm` | `cNrm` | Normalized consumption |
| `\mNrm` | `mNrm` | Normalized market resources |
| `\PermGroFac` | `PermGroFac` | Permanent income growth factor |
| `\LivPrb` | `LivPrb` | Survival probability |
| `\permShk` | `permShk` | Permanent income shock |
| `\tranShk` | `tranShk` | Transitory shock (generic) |

Shock variable names use **lowercase initial** in both LaTeX and Python (e.g. `\permShk` = `permShk`), matching the LaTeX convention. HARK API dictionary keys (e.g. `"PermShkStd"`, `"TranShkCount"`) retain uppercase as required by HARK's interface.

When writing new code, follow this convention. When editing LaTeX macros, check whether the corresponding code needs updating (and vice versa).

---

## `prompts/` — AI-assisted work history

The `prompts/` directory contains markdown files documenting prior AI-assisted sessions. These cover:

- Deep mathematical audits of the LaTeX against formal frameworks.
- Notation harmonization between this document and the `bellman-ddsl` unified framework.
- Restructuring proposals (e.g. portfolio choice section, four-period examples).
- Equation mapping ("Rosetta stone") between different notation systems.

These are **canonical reference material**, not throwaway chat logs. Consult them when working on the same topics they address.

---

## The Jupyter notebook

The primary user-facing artifact is **`SolvingMicroDSOPs.ipynb`** at the repo root. It walks through every method in the document, from brute-force value function maximization through EGM, multi-period backward induction, portfolio choice, and cross-validation against HARK.

The notebook imports from several helper modules:

| Module | Role |
|--------|------|
| `Code/Python/notebook_params.py` | Parameters shared across all notebook cells (DiscFac, CRRA, Rfree, grids, etc.) |
| `Code/Python/notebook_solvers.py` | Functions that solve the consumption and portfolio problems for each method |
| `Code/Python/notebook_plots.py` | All plotting functions — each produces one figure shown in the notebook |
| `Code/Python/period_types.py` | Defines the stage composition of each period type (consumption-only, portfolio, etc.) |
| `Code/Python/solve.py` / `solve_modular.py` | The modular backward-induction solver called by `notebook_solvers` |

When editing the notebook, keep in mind:

- **Markdown cells** provide narrative that echoes (but abbreviates) the LaTeX document. They are not a substitute for the full math.
- **Code cells** import from the modules above. If you need to change solver behavior, edit the `.py` module rather than inlining code in the notebook.
- **Plots** are generated by calling functions from `notebook_plots.py`. These functions use `plt.show()` internally; do **not** `return fig` (this causes duplicate display in Jupyter's inline backend).

---

## Worked example: tracing the Euler equation from LaTeX to Python

This example shows the full pipeline from a single equation in the LaTeX source through to its implementation in code.

### 1. LaTeX source (`_sectn-the-usual-theory.tex`, line ~71)

```latex
\uFunc^{\partial}(\cNrm_{\prdt}) = \ExEndPrd[\DiscFac \Rfree \PermGroFac_{\prdt+1}^{-\CRRA} \uFunc^{\partial}(\cNrm_{\prdt+1})]
```

This is the Euler equation for consumption (label `eq:cEuler`). It says: marginal utility today equals the expected discounted marginal utility tomorrow.

### 2. CodeInfo annotation (same file, line ~77)

```
%% CodeInfo:eq label=eq:cEuler; computes=Euler equation for consumption across periods;
%%   inputs=cNrm_t, DiscFac, Rfree, PermGroFac, tranShkEmp dist, cNrm_tp1;
%%   outputs=cNrm_t (implicitly)
```

This structured comment tells an AI (or tooling) what the equation computes and what it depends on.

### 3. Python implementation (`Code/Python/endOfPrd.py`)

The end-of-period value function class `EndOfPrd` implements the RHS of the Euler equation:

```python
vCntnδ(a)   # ≡ E[β R Γ^{-ρ} u'(c_{t+1})]  — marginal end-of-period value
```

This is the expected discounted marginal utility, computed by numerical integration over the discretized shock distribution. The variable name `vCntnδ` mirrors the LaTeX `\vEndPrd^{\delta a}`.

### 4. EGM inversion (`Code/Python/notebook_solvers.py`)

Rather than rootfinding on the Euler equation, the Endogenous Grid Method *inverts* it:

```
c = u'^{-1}(vCntnδ(a))     →    cNrm = vCntnδ(a_grid) ** (-1/CRRA)
```

This gives consumption directly as a function of end-of-period assets, which is then paired with `m = a + c` to build the consumption function on an endogenous grid.

---

## What you should do when making changes

1. **If you add or change a figure**: write (or update) the Python code that generates it, place the output in `Figures/`, and ensure the LaTeX `\includegraphics` path matches.
2. **If you add or change a table**: write (or update) the Python code that generates the data, and update the LaTeX table fragment in `Tables/`.
3. **If you rename a macro in LaTeX**: grep the Python code for the old name and update it.
4. **If you add a new equation**: consider whether it belongs in `Equations/` as a reusable fragment.
5. **If you create a new section**: follow the `subfiles` pattern (see `orientation-latex-math.md` in this directory).
6. **Move toward full reproducibility**: whenever you encounter a static/legacy figure, consider whether it's feasible to replace it with a Python-generated version.
